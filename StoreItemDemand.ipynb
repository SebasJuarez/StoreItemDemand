{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07b550c",
   "metadata": {},
   "source": [
    "# Laboratorio 8 - Deep Learning y sistemas inteligentes\n",
    "### Repo: https://github.com/SebasJuarez/StoreItemDemand\n",
    "### Sebastian Juárez - 21471\n",
    "### Javier Prado - 21486\n",
    "### Bryan España - 21550"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d449f3d",
   "metadata": {},
   "source": [
    "### Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc994ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sebas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = \"./Data\"\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "HORIZON_DAYS = 90\n",
    "WINDOW_SIZE  = 180\n",
    "MIN_SERIES_LEN = WINDOW_SIZE + HORIZON_DAYS + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110caf55",
   "metadata": {},
   "source": [
    "### Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba6c8c",
   "metadata": {},
   "source": [
    "#### Limpieza de celdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  store  item  sales\n",
      "0 2013-01-01      1     1     13\n",
      "1 2013-01-02      1     1     11\n",
      "2 2013-01-03      1     1     14\n",
      "3 2013-01-04      1     1     13\n",
      "4 2013-01-05      1     1     10\n",
      "date     0\n",
      "store    0\n",
      "item     0\n",
      "sales    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train[\"date\"] = pd.to_datetime(train[\"date\"])\n",
    "train = train.sort_values([\"store\",\"item\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(train.head())\n",
    "print(train.isna().sum())\n",
    "\n",
    "\n",
    "if train[\"sales\"].isna().any():\n",
    "    train[\"sales\"] = train[\"sales\"].fillna(0)\n",
    "\n",
    "def winsorize_series(s, k=1.5):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - k*iqr, q3 + k*iqr\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "train[\"sales_w\"] = (\n",
    "    train.groupby([\"store\",\"item\"])[\"sales\"]\n",
    "         .transform(lambda s: winsorize_series(s))\n",
    ")\n",
    "\n",
    "train[\"sales_log\"] = np.log1p(train[\"sales_w\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574516b",
   "metadata": {},
   "source": [
    "#### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127ba04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>date</th>\n",
       "      <th>sales_log</th>\n",
       "      <th>dow_s</th>\n",
       "      <th>month_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  item       date  sales_log     dow_s  month_s\n",
       "0      1     1 2013-01-01   2.639057  0.166667      0.0\n",
       "1      1     1 2013-01-02   2.484907  0.333333      0.0\n",
       "2      1     1 2013-01-03   2.708050  0.500000      0.0\n",
       "3      1     1 2013-01-04   2.639057  0.666667      0.0\n",
       "4      1     1 2013-01-05   2.397895  0.833333      0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"dow\"]   = train[\"date\"].dt.dayofweek\n",
    "train[\"month\"] = train[\"date\"].dt.month\n",
    "\n",
    "train[\"dow_s\"]   = train[\"dow\"]   / 6.0\n",
    "train[\"month_s\"] = (train[\"month\"] - 1) / 11.0\n",
    "\n",
    "feat_cols = [\"sales_log\", \"dow_s\", \"month_s\"]\n",
    "key_cols  = [\"store\",\"item\",\"date\"]\n",
    "data = train[key_cols + feat_cols].copy()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd682a6",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407ffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Última fecha: 2017-12-31 | Inicio de valid: 2017-10-03\n"
     ]
    }
   ],
   "source": [
    "last_date = data[\"date\"].max()\n",
    "val_start = last_date - pd.Timedelta(days=HORIZON_DAYS-1)\n",
    "\n",
    "print(\"Última fecha:\", last_date.date(), \"| Inicio de valid:\", val_start.date())\n",
    "\n",
    "data[\"split\"] = np.where(data[\"date\"] >= val_start, \"valid\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e34228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((733500, 180, 3), (733500, 90), (45000, 180, 3), (45000, 90))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_sequences(df_one_series, window=WINDOW_SIZE, horizon=HORIZON_DAYS):\n",
    "    feats = df_one_series[feat_cols].values\n",
    "    dates = df_one_series[\"date\"].values\n",
    "    splits = df_one_series[\"split\"].values\n",
    "\n",
    "    X_tr, y_tr, X_va, y_va = [], [], [], []\n",
    "\n",
    "    for start in range(0, len(df_one_series) - (window + horizon) + 1):\n",
    "        end_w = start + window\n",
    "        end_h = end_w + horizon\n",
    "\n",
    "        X_win = feats[start:end_w]\n",
    "        y_win = df_one_series[\"sales_log\"].values[end_w:end_h]\n",
    "\n",
    "        target_last_date = df_one_series[\"date\"].iloc[end_h - 1]\n",
    "        if target_last_date >= val_start:\n",
    "            X_va.append(X_win)\n",
    "            y_va.append(y_win)\n",
    "        else:\n",
    "            X_tr.append(X_win)\n",
    "            y_tr.append(y_win)\n",
    "\n",
    "    return X_tr, y_tr, X_va, y_va\n",
    "\n",
    "X_train, y_train, X_valid, y_valid = [], [], [], []\n",
    "\n",
    "for (st, it), g in data.groupby([\"store\",\"item\"]):\n",
    "    g = g.sort_values(\"date\")\n",
    "    if len(g) < MIN_SERIES_LEN:\n",
    "        continue\n",
    "    Xt, yt, Xv, yv = build_sequences(g)\n",
    "    if Xt:\n",
    "        X_train.extend(Xt)\n",
    "        y_train.extend(yt)\n",
    "    if Xv:\n",
    "        X_valid.extend(Xv)\n",
    "        y_valid.extend(yv)\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "X_valid = np.array(X_valid, dtype=np.float32)\n",
    "y_valid = np.array(y_valid, dtype=np.float32)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04eb473",
   "metadata": {},
   "source": [
    "### Modelado - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4210b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sebas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"lstm_forecaster\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 180, 3)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 180, 64)           17408     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 64)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 90)                5850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37786 (147.60 KB)\n",
      "Trainable params: 37786 (147.60 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = X_train.shape[1]\n",
    "n_features  = X_train.shape[2]\n",
    "n_outputs   = y_train.shape[1]\n",
    "\n",
    "def build_lstm_model(timesteps, nfeat, horizon):\n",
    "    inputs = keras.Input(shape=(timesteps, nfeat))\n",
    "    x = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.LSTM(32)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(horizon, activation=\"linear\")(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"lstm_forecaster\")\n",
    "    return model\n",
    "\n",
    "model = build_lstm_model(n_timesteps, n_features, n_outputs)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
